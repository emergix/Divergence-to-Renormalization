# Unifying Divergences Across Domains

This document, titled **"Unifying Divergences Across Domains: From Physics to Learning and Finance"** by Olivier Croissant, presents a profound and mathematically rigorous exploration of how divergence functions—such as relative entropy and Bregman divergences—form a unifying thread across physics, machine learning, and financial mathematics.

## Summary

The report is structured into four main chapters and multiple technical appendices:

### 1. **Laws of Nature and Divergences**
The document begins by showing how divergence functions govern renormalization group flows in quantum field theory. This includes a reinterpretation of Polchinski’s equation as a gradient flow in probability space using Wasserstein geometry and relative entropy.

### 2. **Divergences in Generative Learning**
In high-dimensional learning, particularly diffusion models for image and text generation, divergences guide the transition from noise to meaningful output via stochastic differential equations. These models reflect a time-symmetric process that parallels renormalization.

### 3. **Financial Derivative Hedging**
Divergences also appear in finance, modeling dynamic hedging strategies under constraints. By minimizing divergence between cost and payoff, and using Taylor-like expansions, one can refine hedging approaches—combining financial modeling with neural optimization.

### 4. **Technical Appendices**
The appendices detail the mathematical structure of divergences:
- Information geometry foundations (Riemannian structure, Bregman divergences, dual coordinates)
- Generalized Pythagorean theorem
- Chaos decomposition in stochastic systems
- Quantum field theory reformulated through divergence flow
- Polchinski’s equation as a gradient flow

## Highlights
- Geometry induced by divergences
- Taylor-like decomposition for iterative refinement
- Duality and symplectic interpretations
- Application to chaos expansions in generative models
- Diffusion-like renormalization in quantum field theory

## References
The paper synthesizes cutting-edge research, citing works such as Cotler-Rezchikov (2022), Deep Hedging by Buehler et al. (2019), and seminal sources in Malliavin calculus and diffusion models.

## Link to Full PDF
You can access the full document here:
[Divergence_based.pdf](./pdf/Divergence_based.pdf)
